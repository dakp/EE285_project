{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Adapted from Sasank Chilamkurthy pytorch tutorial for image classification.\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '../StateFarmDistractedDriverDetection/dataset'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train','val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train','val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train','val']}\n",
    "print(dataset_sizes)\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network used\n",
    "#model_ft = models.alexnet(pretrained =True)\n",
    "model_ft = models.resnet18(pretrained= True)\n",
    "#model_ft = models.vgg16(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (model_ft.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the following for AlexNet\n",
    "net = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "model_ft.classifier = net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the following for VGG-16\n",
    "net = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "        )\n",
    "model_ft.classifier = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except for the final fully connected layer.\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the following for AlexNet\n",
    "### Replace the final layer to classify into one of 10 classes.\n",
    "net2 = nn.Linear(4096, 10)\n",
    "model_ft.classifier.add_module('classify',net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the following for Resnet18\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this for VGG-16 \n",
    "### Replace the final layer to classify into one of 10 classes.\n",
    "net2 = nn.Linear(4096, 10)\n",
    "model_ft.classifier.add_module('classify',net2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model_ft = model_ft.cuda()\n",
    "    print (\"Transfer model to GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this for AlexNet\n",
    "#optimizer = optim.SGD(model_ft.classifier.classify.parameters(),lr=0.001, momentum=0.9)\n",
    "\n",
    "# Use this for Resnet18\n",
    "optimizer = optim.SGD(model_ft.fc.parameters(),lr=0.001, momentum=0.9)\n",
    "\n",
    "# Use this for VGG16\n",
    "#optimizer = optim.SGD(model_ft.classifier.classify.parameters(),lr=0.001, momentum=0.9)\n",
    "\n",
    "# Can add other args such as weight decay etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Adam\n",
    "# learning_rate = 0.001\n",
    "# optimizer = optim.Adam(model_ft.fc.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "NB = math.ceil(len(image_datasets['train']) /batch_size) \n",
    "NB = int(NB)\n",
    "print (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "accu_test = 0.0\n",
    "train_accu = 0.0\n",
    "Time=[]\n",
    "testaccu = []\n",
    "trainloss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    train_accu = 0.0\n",
    "    correct = 0\n",
    "    # Set model to training mode\n",
    "    model_ft.train()\n",
    "    t0 = time.time()   \n",
    "    for i,(inputs,classes) in enumerate(dataloaders['train'],0):\n",
    "        \n",
    "        # Obtain a batch of training data\n",
    "        inputs = inputs.cuda()\n",
    "        classes = classes.cuda()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward\n",
    "        inputs = ag.Variable(inputs,requires_grad=True)\n",
    "        classes = ag.Variable(classes, requires_grad =False)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        # Error evaluation\n",
    "        loss = criterion(outputs,classes)\n",
    "        \n",
    "        # Back Propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Parameter update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print training loss per epoch\n",
    "        running_loss += loss[0]\n",
    "        if i%313 == 312:\n",
    "            print ('[%d] train loss: %.3f'% (epoch+1, np.mean(running_loss.cpu().data.numpy())))\n",
    "            trainloss.append(np.mean(running_loss.cpu().data.numpy()))\n",
    "        running_loss = 0.0\n",
    "    \n",
    "    \n",
    "# Run trained model on test data\n",
    "    for i,(inputs,classes) in enumerate(dataloaders['val'],0):\n",
    "        inputs = inputs.cuda()\n",
    "        classes = classes.cuda()\n",
    "        inputs = ag.Variable(inputs,requires_grad=True)\n",
    "        classes = ag.Variable(classes, requires_grad =False)\n",
    "        outputs = model_ft(inputs)\n",
    "    \n",
    "    # Calculate Accuracy\n",
    "        outputs_np = outputs.cpu().data.numpy().T.argmax(axis=0)\n",
    "        classes_np = classes.cpu().data.numpy()\n",
    "    \n",
    "        correct += np.mean(np.equal(classes_np,outputs_np))\n",
    "    testaccu.append(correct/len(dataloaders['val'])*100)\n",
    "    #     print accuracy per epoch\n",
    "    print ('[%d] testaccu %.3f'% (epoch+1, correct/len(dataloaders['val'])*100))\n",
    "    print('{} seconds'.format(time.time() - t0))\n",
    "    Time.append(time.time() - t0)\n",
    "print (\"Finished Training\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results for plotting\n",
    "data_array_1 = np.array(Time)\n",
    "data_array_2 = np.array(testaccu)\n",
    "data_array_3 = np.array(trainloss)\n",
    "# saving...\n",
    "np.savetxt('time_ResNet.csv',data_array_1,delimiter=',')\n",
    "np.savetxt('testaccu_ResNet.csv',data_array_2,delimiter=',')\n",
    "np.savetxt('trainloss_ResNet.csv',data_array_3,delimiter=',')\n",
    "print ('Finish saving csv file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet accuracy is 73.10385338345865591\n",
    "# Resnet accuracy is 94.54534774436091027\n",
    "# Vgg16 accuracy is 81.29934210526316463"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
